//
// Camguru dataflow engine configuration format.
// Camguru dataflow is a directed acyclic even graph consisting of data and process nodes.
//

syntax = "proto2";

import "ultinous/proto/common/content_type.proto";
import "ultinous/proto/detectionhistory/data.proto";
import "ultinous/proto/imageproc/common.proto";

package ultinous.proto.dataflow;


// WARNING: Process nodes are executed in the order of the dataflow.prototxt
// WARNING: There is no ordering amongst them based on dependencies.
// WARNING: Sorry!

enum Chunking {
  NONE = 1;
  MINUTE = 2;
  HOUR = 3;
}

message Point2D {
  required int32 x = 1;
  required int32 y = 2;
}

message Rect2D {
  required int32 x = 1;
  required int32 y = 2;
  required int32 w = 3;
  required int32 h = 4;
}

message DropOffMode
{
  optional uint64 packet_queue_size = 1 [default = 8, jstype=JS_STRING]; // max packet queue size, cannot be 0
  optional uint64 gpu_task_queue_size = 2 [default = 8, jstype=JS_STRING]; // max gpu task queue size, cannot be 0
}

message DropOnMode
{
  optional uint32 packet_time_drop_threshold = 1 [default = 9000]; // max packet age in ms, cannot be 0
  optional uint32 gpu_task_time_drop_threshold = 2 [default = 9000]; // max gpu task age in ms, cannot be 0
  optional uint64 gpu_task_queue_max_memory = 3 [default = 2147483648, jstype=JS_STRING]; // max memory used by gpu task queue, cannot be 0
}

message EnvironmentConfig {
  enum GUIType {
    NO = 0;
    NORMAL = 1;
    OPENGL = 2;
  }

  optional GUIType gui = 2 [default = NO];
  optional bool profile = 3 [default = false];
  optional int32 debug_level = 4 [default = 2];
  optional string log_path = 6 [default = "."]; // See also log_interval_mins at bottom.
  optional bool step_mode = 7 [default = false];
  optional uint32 analysis_thread_count = 8 [default = 1];
  optional int32 max_grpc_message_size = 10 [default = -1]; // maximum gRPC message size in bytes
  optional uint32 log_interval_mins = 11 [default = 60];

  oneof drop_mode {
    DropOffMode drop_off = 12;
    DropOnMode drop_on = 13;
  }

  optional bool rtp_ntp_time = 14 [default = false];
  optional string kafka_broker_list = 15 [ default = "" ]; // Example "localhost:1234,example.com:4321"
  optional string kafka_topic_prefix = 16 [ default = "" ]; // Example "account.1337."
  optional string kafka_sasl_username = 17 [ default = "" ]; // Enables SASL authentication when set.
  optional string kafka_sasl_password = 18 [ default = "" ];
}

message Input {
  // Input file/stream/device name. Can be one of the following:
  //  - single image (eg.: jpg, png)
  //  - video file (eg.: avi, mp4)
  //  - rtsp url
  //  - device id (eg.: 0 - the webcam)
  //  - historic video (eg.: historic:///path/to/stream/data)
  required string file_name = 1;
  optional uint32 image_repeat_dt = 12 [default = 0]; // [ms], 0 = no-repeat

  // In some cases the input video does not contain absolute timestamps (only relative).
  // In this case the start time can be specified as an iso timestamp (eg.: "2013-03-18T03:17:23")
  optional string start_time = 2;

  // optional uint32 fps = 3 [default = 8]; // frames per second
  optional uint32 drop_rate = 4 [default = 1]; // keep every n-th frame

  // Time interval for historic video
  // For a boundary, only one can be set
  optional int64 from_time_ms = 5; // UTC timestamp in milliseconds since UNIX epoch
  optional string from_time = 6;   // human readable timestamp (see utils/inc/ultinous/utils/DateTimeText.h:scanDateTime
  optional int64 to_time_ms = 7;  // UTC timestamp in milliseconds since UNIX epoch
  optional string to_time = 8;     // human readable timestamp (see utils/inc/ultinous/utils/DateTimeText.h:scanDateTime

  optional uint32 capture_width = 9 [default = 0]; // Expected image width for capture device
  optional uint32 capture_height = 10 [default = 0]; // Expected image height for capture device
}

message DataNodeConfig {
  enum Type {
    FRAME = 0; // image
//    reserved 1; // used to be BOUNDING_BOXES; 'reserved' keyword not recognized by JS
    TRACKS = 2;
    SUPER_CROPS = 3;
    SUPER_CROP_BATCHES = 4;
    PASS_COUNTER_DATA = 5; // key-value pairs
    FEATURE_VECTORS = 6;
    GENDERS = 7;
    AGES = 8;
    HEAD_POSE_3DS = 9;
    HEAD_POSES = 10;
    DETECTIONS = 11;
    PASS_EVENTS = 12; // key-value pairs
    FRAME_INFO = 13; // resolution etc.
    SKELETONS = 14;
  }

  required Type type = 1;
  required string name = 2;
}

message ProcessNodeConfig {
  enum Type {
    BACKGROUND_MODEL = 0;
    DISPLAY = 1;
    ROI = 2;
    OBJ_DETECTOR = 3;
    DRAW_RECTS = 4;
    PERSON_PRESENCE_DETECTOR = 5;
    MERGE = 6;
    PASS_COUNTER = 7;
    RESIZE = 8;
    WRITE_VIDEO = 9;
    FACE_REC_DEMO = 10;
    CLASSIF = 11;
    DRAW_TIMESTAMP = 14;
    TRACK = 15;
    DUMMY_ANALYSIS = 17;
    DRAW_TRACKS = 18;
    GENDER_CLASSIF = 19;
    LOOK_ALIKE = 20;
    ROTATE = 21;
    FRAME_SOURCE = 22;
    ANALYSER_LOGGER = 23;
    AVERAGE_IMAGE = 24;
    FRAME_DISPATCHER = 25;
    BLUR = 26;
    DEMOGRAPHY = 27;
    OBJ_DETECTOR_EMULATOR = 28;
    KALMAN_TRACK = 29;
    OBJ_FILTER = 30;
    OBJ_DETECTOR_LOGGER = 31;
    ROTATED_ROI_FILTER = 32;
    ERROR_NODE = 33;
    PERSON_REIDENTIFICATION = 34;
    TRACKLET = 35;
    DETECTION_HISTORY_SERVICE = 36;
    FACE_EXPR = 37;
    HEAD_POSE_FILTER = 38;
    SUPERCROP_EXTRACTOR = 39;
    HEAD_DETECTOR_PUBLISHER = 40;
    TRACKER_PUBLISHER = 41;
    CALC_FACE_REC_FEATURES = 42;
    MATCH_FACE_REC_FEATURES = 43;

    KAFKA_OUTPUT = 44;

    POLY_ROI_FILTER = 45;
    FACIAL_DEMOGRAPHY = 46;
    DRAW_POLYGON = 47;
    DRAW_PASS_COUNTER = 48;
    HEAD_POSE_CALC = 51;
    FACE_FEATURE_CALC = 52;
    FACE_DEMOGRAPHY_CALC = 53;
    PASS_EVENTS_LOGGER = 54;
    FULL_BODY_CROP_BOX_CALC = 55;
    FULL_BODY_FEATURE_CALC = 56;
    FRAME_INFO_EXTRACTOR = 57;
    SKELETON_ESTIMATOR = 58;
    DRAW_SKELETON = 59;
  }

  required Type type = 1;
  required string name = 2;
  optional bool logging = 3 [default = false];

  // Polymorphism is implemented with optional process specific fields.
  // Exactly one of these must be specified based on the type.
  optional BackgroundModelConfig background_model_config = 4;
  optional DisplayConfig display_config = 5;
  optional ROIConfig roi_config = 6;
  optional ObjDetectorConfig obj_det_config = 7;
  optional DrawRectsConfig draw_rects_config = 8;
  optional PersonPresenceDetectorConfig person_presence_det_config = 9;
  optional PassCounterConfig pass_counter_config = 10;
  optional MergeConfig merge_config = 11;
  optional ResizeConfig resize_config = 12;
  optional WriteVideoConfig writevideo_config = 13;
  optional FaceRecConfig face_rec_config = 14;
  optional ClassifierNodeConfig classifier_config = 15;
  optional DrawTimestampConfig draw_timestamp_config = 18;
  optional TrackConfig track_config = 19;
  optional DummyAnalysisConfig dummy_analysis_config = 21;
  optional DrawTracksConfig draw_tracks_config = 22;
  optional GenderClassifConfig gender_classif_config = 23;
  optional LookAlikeConfig look_alike_config = 24;
  optional RotateConfig rotate_config = 25;
  optional FrameSourceConfig frame_source_config = 26;
  optional AnalyserLoggerConfig analyser_logger_config = 30;

  // Give coherent process nodes the same area id.
  // Coherent process nodes are working on the same area (e.g. processing the same ROI).
  // For example, ageA and genderA process nodes should belong to area 0,
  // ageB and genderB process nodes should belong to area 1
  optional int32 area_id = 27 [default = 0];

  optional string extra_field_name = 28 [default = ""]; // one optional extra field in csv logging
  optional string extra_field_value = 29 [default = ""];

  optional AverageImageConfig average_image_config = 31;
  optional FrameDispatcherConfig frame_dispatcher_config = 32;
  optional BlurConfig blur_config = 33;
  optional DemographyNodeConfig demography_config = 34;
  optional ObjDetectorEmulatorConfig obj_det_emulator_config = 35;
  optional KalmanTrackConfig kalman_track_config = 36;
  optional ObjFilterNodeConfig obj_filter_config = 37;
  optional ObjDetectorLoggerNodeConfig obj_logger_config = 38;
  optional RotatedRoiFilterConfig rotated_roi_filter_config = 39;
  optional ErrorThrowNodeConfig error_node_config = 40;
  optional PersonReidentificationConfig person_reidentification_config = 41;
  optional TrackletConfig tracklet_config = 42;
  optional DetectionHistoryService detection_history_service_config = 43;
  optional FaceExprConfig face_expr_config = 44;
  optional HeadPoseFilterConfig head_pose_filter_config = 45;
  optional SupercropExtractorConfig supercrop_extractor_config = 46;
  optional HeadDetectorPublisherConfig head_detector_publisher_config = 47;
  optional TrackerPublisherConfig tracker_publisher_config = 48;
  optional CalcFaceRecFeaturesConfig calc_face_rec_features_config = 49;
  optional MatchFaceRecFeaturesConfig match_face_rec_features_config = 50;
  optional KafkaOutputConfig kafka_output_config = 51;

  optional PolyRoiFilterConfig poly_roi_filter_config = 52;
  optional FacialDemographyNodeConfig facial_demography_config = 53;
  optional DrawPolygonConfig draw_polygon_config = 54;
  optional DrawPassCounterConfig draw_pass_counter_config = 55;
  optional HeadPoseCalcConfig head_pose_calc_config = 60;
  optional FaceFeatureCalcConfig face_feature_calc_config = 61;
  optional FaceDemographyCalcConfig face_demography_calc_config = 62;
  optional PassEventsLoggerConfig pass_events_logger_config = 63;
  optional FullBodyCropBoxCalcConfig full_body_crop_box_calc_config = 64;
  optional FullBodyFeatureCalcConfig full_body_feature_calc_config = 65;
  optional FrameInfoExtractorConfig frame_info_extractor_config = 66;
  optional SkeletonEstimatorNodeConfig skeleton_estimator_config = 67;
  optional DrawSkeletonConfig draw_skeleton_config = 68;
}

//
// Computes a background model for background/foreground separation.
// Detecting the foreground can significantly speed up further processing sich as object detection.
//
message BackgroundModelConfig {
  required string input = 1; // type: FRAME
  required string change_mask = 2; // A mask image showing foreground with white and background with black. (type: FRAME)
  optional string background = 3; // The background model for debug purposes. (type: FRAME)
  optional imageproc.BackgroundModelConfigParams params = 4;
}

//
// Displays frames in a separate window. User interface support (eg.:X) must be available in the execution environment.
//
message DisplayConfig {
  required string frame = 1; // type: FRAME

  // Updates the display every update_period frames. Displaying every single frame can slow down graph execution.
  // With this parameter the the trade-off between speed and display responsiveness can be set.
  optional uint32 update_period = 2 [default = 1];
}

//
// Cut a region of interest (ROI) from a frame.
//
message ROIConfig {
  required string input = 1; // type: FRAME
  required string output = 2; // type: FRAME

  required int32 x = 3; // x coordinate of the top left corner in pixels
  required int32 y = 4; // y coordinate of the top left corner in pixels
  required int32 width = 5; // in pixels
  required int32 height = 6; // in pixels
}

//
// Object detector. Find objects on a frame. Objects are returend as bounding boxes.
//
message ObjDetectorConfig {
  enum Type {
    FACE = 1;
    HEAD = 2;
  }

  required Type type = 1;
  required string input = 2; // type: FRAME

  // Image mask. Black (0) values mean background, white (255) means foreground.
  // If specified it can speed up processing significantly by not searching for object on background regions.
  // BackgroundModelConfig outputs a mask like this.
  // type: FRAME
  optional string input_mask = 3;

  // output
  required string bounding_boxes = 4; // type: DETECTIONS

  // Size of the smallest square that fully contains the object. Detection performance and accuracy drops as the size gets smaller.
  // Size below 30-40 pixels are not suggested in real-world applications.
  optional int32 min_height_in_pixels = 5 [default = 160];
  optional int32 max_height_in_pixels = 6 [default = 160];

  optional float confidence_threshold = 7 [default = 0.95]; // Confidence is a real value from 0-1.

  optional int32 cam_id = 8 [default = 0];

  optional uint32 alternating_mode_period = 9 [default = 0]; // speed-up: run object detector on every n-th frame when there are no detected objects (n=0: turned off)
  optional uint32 tracking_mode_period = 10 [default = 0]; // speed-up: run object detector on the surrounding of an object if there was only one; run a full scan on every n-th frame (n=0: turned off)

  optional float image_scale_factor = 11 [default = 1.0]; // This parameter explicitly resize the input frame.

}

message ObjDetectorLoggerNodeConfig {
  enum OutputType {
    CSV = 1;
    RPC = 2;
    KAFKA = 3;
  }
  enum VarianceMode {
    USE_ONLY = 1;
    LOG_ONLY = 2;
    USE_AND_LOG = 3;
  }

  optional string object_detector_node_name = 1 [deprecated = true]; // use the two below
  optional string input_frame = 12;
  optional string input_boxes = 13;

  optional bool produce_bounding_box_output = 2 [default = true];
  optional bool tracking_log = 3 [default = false]; // yet another logging to stdout for the tracking demo

  optional bool force_bool = 4 [default = false]; // Use BOOLEAN signal type instead of NATURAL. With BOOLEAN signal type, signal value is 1 iff there was more than 1 detection.

  optional uint32 variance_size_threshold = 5 [default = 15]; // minimal number of bounding boxes to use variance_value_threshold (see below)
  optional float variance_value_threshold = 6 [default = 0.005]; // ignore detected bounding boxes if the variance of the position of the latest bounding box(es) is lower than this value
  optional uint32 variance_window_size = 7 [default = 60];

  optional VarianceMode variance_usage_mode = 14 [default = USE_ONLY]; // variance parameters must be defined in the config file as well!
  optional uint32 variance_log_update_period = 15 [default = 10];

  optional float counter_momentum = 8 [default = 0.95];

  optional uint32 output_period = 9 [default = 1]; // produce log and signal output at every output_period frames

  repeated OutputType output_type = 10 [packed = true];
  optional uint32 rpc_listen_port = 11 [default = 0];

  // Final topic name: EnvironemntConfig.kafka_topic_prefix + kafka_topic + ".detection.StabilizedObjectDetection.json"
  // If not set then process node name will be used.
  optional string kafka_topic = 16 [default =""];
}

//
// Draw rectangles on a frame. Blurring, and full image blackout is also supported to meet with different privacy requirements
//
message DrawRectsConfig {
  enum DrawBoundingBoxType {
    FRAME = 1;
    FILL = 2;
  }

  required string input_frame = 1; // type: FRAME
  required string output_frame = 2; // type: FRAME
  required string input_bounding_boxes = 3; // type: DETECTIONS
  optional string input_tracks = 4; // type: TRACKS

  required imageproc.RGB det_color = 5; // rgb color for the rectangles and fill if there is detection
  optional imageproc.RGB no_det_color = 6; // rgb color for fill if no detection

  optional bool blur = 7 [default = false]; // if set blurring applied to all detection with blur_kernel_size and blur_sigma parameters
  optional int32 blur_kernel_size = 8 [default = 31];
  optional float blur_sigma = 9 [default = 20];

  optional bool draw_rect = 10 [default = true]; // if set bounding boxes are drawn
  optional float draw_rect_threshold = 11 [default = 0.0];  // threshold filter for bounding boxes
  optional bool draw_properties = 12 [ default = true ]; // write out explicitly added properties, like confidence, gender, name etc
  optional bool draw_score = 21; // write out score, defaults to draw_properties.
  optional double draw_properties_scale = 22 [ default = 0.7 ]; // Scaling factor for rendering font

  optional bool fill_if_det = 13 [default = false]; // if set the full image is filled with det_color if there is at least one detection
  optional bool fill_if_no_det = 14 [default = false ]; // if set the full image is filled with no_det_color if there no detection

  optional int32 input_bounding_boxes_offset_x = 15 [default = 0];
  optional int32 input_bounding_boxes_offset_y = 16 [default = 0];

  optional float head_padding_top = 17 [default = 0];
  optional float head_padding_right = 18 [default = 0];
  optional float head_padding_bottom = 19 [default = 0];
  optional float head_padding_left = 20 [default = 0];

  // FRAME: draw a nice frame around the bounding boxes. FILL: fill the bounding boxes entirely.
  // Color is defined by det_color. Only works if draw_rect is true, obviously.
  optional DrawBoundingBoxType draw_bounding_box_type = 23 [default = FRAME];

  // Draw bounding box height as property. Works only if draw_properties is true.
  optional bool draw_bounding_box_height_properties = 24 [default = false];
}

message PersonPresenceDetectorConfig {
  required string input = 1;
  // required string result = 2;
  optional float confidence_threshold = 3 [default = 0.5];
}

//
// Merge multiple images to one. Typically can be used to display or debug purposes.
//
message MergeConfig {
  message InputCfg
  {
    required string input = 1;
    optional int32 x = 2 [default = 0]; // x offset for absolute mode
    optional int32 y = 3 [default = 0]; // y offset for absolute mode
  }

  enum Type {
    KEEP_SIZE = 1; // Use the biggest image size as cell size for each image. Center images in cells.
    KEEP_AR = 2; // We define the output image size and calculate k equal cell size (k>=n). We resize inputs to fit to cell size, with fix aspect ratio.
    RESIZE = 3; // Same method as KEEP_AR, just resize go with no fix aspect ratio.
    KEEP_AR_WITH_RATES = 4; // User can specify offset for each input. This mode is optimized for GPU.
    ABSOLUTE = 5;
  }

  optional Type type = 1 [default = KEEP_AR];
  optional int32 width = 2 [default = 1280];
  optional int32 height = 3 [default = 720];
  repeated InputCfg inputs = 4;
  required string output = 5;
  repeated float hrates = 6; // sets the horizontal rates, the last one is repeated if the inputs size too large
  repeated float vrates = 7; // sets the vertical rates, the last one is repeated if the inputs size too large
  optional bool show_input_names = 8 [default = true];
  optional float font_resize = 9 [default = 2.0];
}

//
// Person passage counter. Count how many people crosses a given line in each direction (in/out).
// Crossing event occures when the boundig box of the head of a person crosses the specified line.
//
message PassCounterConfig {
  message PassLine {
    repeated Point2D line = 1;
    // from -> to means out -> in,  must cross the passline
    required Point2D from = 2;
    required Point2D to = 3;
  }

  required string input_tracks = 1;
  optional string input_frame = 2 [deprecated = true];
  optional string output_frame = 3 [deprecated = true];
  optional string output_data = 4; // -> PASS_COUNTER_DATA Forever increasing in and out count

  // Points of the polygon.
  repeated Point2D polygon = 5 [deprecated = true]; // it's not a polygon, it's a polyline
  optional int32 delay = 6 [default = 2000]; // delay time before registering an active track's pass (ms); 0 means infinite

  optional int32 engine_id = 7 [default = 1];
  optional bool flip_in_and_out = 8 [default = false, deprecated = true]; // flip the in and the out during counting
  optional bool display_in_only = 9 [default = false]; // display only IN and SUM attributes
  optional float font_resize = 10 [default = 2.0];

  optional PassLine passline = 11;
  optional string output_events = 12; // -> PASS_EVENTS. In and out events as they occur with track ids
  optional bool add_passing_direction = 13 [default = true];
  optional bool ignore_extrapolated_tracks = 14 [default = false]; // do not count passages if the track has no detection after the passage
}

message DrawPassCounterConfig {
  required string input_frame = 1;
  required string output_frame = 2;
  required string input_pass_counter_data = 3;
  optional bool display_in_only = 4 [default = false]; // display only IN and ACT counters. display_counters must also be true.
  optional float font_resize = 5 [default = 2.0];
  optional int32 offset_x = 6 [default = 0];
  optional int32 offset_y = 7 [default = 0];
  optional bool display_counters = 8 [default = true]; // display counters
}

message PassEventsLoggerConfig
{
  enum OutputType {
    CSV = 1;
    KAFKA = 3;
  }
  required string input_events = 1; // -> PASS_EVENTS
  repeated OutputType output_type = 2 [packed = true];
  // Final topic name: EnvironemntConfig.kafka_topic_prefix + kafka_topic + ".pass.Pass.json"
  // If not set then process node name will be used.
  optional string kafka_topic = 3 [default =""];
}

message TrackConfig {
  required string input = 1;
  required string output = 2;
  optional double alpha = 3 [default = 0.25]; // weight of the average
  optional double min_observation_score = 4 [default = 0.2]; // score of the best observation
  optional bool use_score = 5 [default = true]; // use the score of the detection to scale the IOU
}

message ResizeConfig {
  enum Type {
    ABSOLUTE_SIZE = 1;
    RELATIVE_SIZE = 2;
  }
  enum Interpolation {
    INTER_NEAREST = 1;
    INTER_LINEAR = 2;
    INTER_CUBIC = 3;
  }
  required Type type = 1;
  required string input = 2;
  required string output = 3;
  optional bool lock_ar = 4 [default = true];
  optional int32 width = 5;
  optional int32 height = 6;
  optional Interpolation interpol = 7 [default = INTER_LINEAR];

  optional string input_tracks = 8;
  optional string output_tracks = 9;

  // if resizeWarning is set true, a warning is logged in case resize actually happens (because this is an issue, either up- or downsizing)
  optional bool resizeWarning = 10 [default = false];
}

message FrameDispatcherConfig
{
  required string input_frame = 1;
}

message BlurConfig
{
  required string input_frame = 1;
  required string output_frame = 2;
  optional int32 blur_kernel_size = 3 [default = 31];
  optional float blur_sigma = 4 [default = 20];
}

//
// Write frames to a file.
//
message WriteVideoConfig {
  required string file_name = 2; // filename without extension
  required string file_ext = 3; // Extension that defines the video container format. Supported formats: mp4, avi
  required string input = 4; // type: FRAME

  optional uint32 fps = 5; // force output fps

  // Video codec. Supported codecs depend on OS environment. A portable example: "FMP4"
  required string codec = 6;

  // If set the files will be split into minute or hour long chunks on minute/hour boundaries.
  optional Chunking chunking = 7 [default = NONE];
  optional uint32 max_queue_size = 8 [default = 1024];
}

enum BorderType {
  BORDER_TYPE_NONE = 1;
  BORDER_TYPE_SIMPLE = 2;
  BORDER_TYPE_SALIENT = 3;
}

message SpecialSubject {
  required string subject_id = 1;
  optional imageproc.RGB color = 2;
}

message FaceRecConfig {
  required string input_image = 1;
  required string input_boxes = 2;
  required string output_image = 3;
  required string database_path = 4;
  optional bool use_head_pose_model = 8 [default = true];
  optional float head_pose_threshold = 9 [default = 0.5];
  optional float head_pose_threshold_for_registration = 10 [default = 0.8];
  optional bool register_mode = 11 [default = true];
  optional uint32 max_num_faces = 12 [default = 0];
  optional uint32 min_size_for_recognition = 13 [default = 128];
  optional uint32 rec_initial_batch_size = 14 [default = 0];
  optional uint32 pose_initial_batch_size = 15 [default = 0];
  optional bool draw = 16 [default=true];

  optional bool demography = 17 [default=false];
  optional bool show_age = 50 [default = true];
  optional bool show_gender = 51 [default = true];
  optional string age_prefix = 52 [default = "Age:"];
  optional string gender_prefix = 53 [default = "Gender:"];
  optional uint32 age_smooth = 54 [default = 8];

  optional imageproc.RGB color_unused_face = 18;
  optional imageproc.RGB color_recognized = 19;
  optional imageproc.RGB color_recognized_autoreg = 20;
  optional imageproc.RGB color_to_register = 21;
  optional imageproc.RGB color_uncertain = 22;
  optional imageproc.RGB color_too_small = 23;

  optional float font_scale = 30 [default = 1.0];
  optional uint32 font_thickness = 31 [default = 1];

  optional BorderType text_border = 32 [default = BORDER_TYPE_NONE];
  optional float text_border_thickness = 33 [default = 1.0];
  optional imageproc.RGB text_border_color = 34;

  optional BorderType box_border = 35 [default = BORDER_TYPE_NONE];
  optional float box_border_thickness = 36 [default = 1.0];
  optional imageproc.RGB box_border_color = 37;

  optional string auto_reg_prefix = 39 [default=""];

  optional uint32 min_num_samples_to_register = 40 [default = 10];

  optional double recognition_far = 41 [default = 0.001];
  optional double uncertainty_far = 42 [default = 0.01];

  optional bool anonimize_unrecognized_faces = 43 [default = false];
  optional bool write_head_count = 44 [default = false];
  optional string head_count_prefix = 45 [default = ""];
  optional float head_count_scale = 46 [default = 1.0];
  optional imageproc.RGB head_count_color = 47;

  repeated SpecialSubject special_subject = 48;
  optional bool draw_head_count = 49 [default = false];
}

message ClassifierNodeConfig {
  enum Type {
    FACIAL_AGE = 1;
    FACIAL_GENDER = 2;
    FACIAL_EXPRE = 3;
    IMAGENET = 4;
  }
  required Type type = 1;
  required string input_image = 2;
  required string input_boxes = 3;
  optional float confidence_threshold = 4 [default = 1];
  optional string label = 5 [default = "Label"];
  required string output_boxes = 6;
}

//
// Draw millisecond resolution timestamp to the frames for debug purposes
//
message DrawTimestampConfig {
  required string input_frame = 1; // type: FRAME
  required string output_frame = 2; // type: FRAME
  required imageproc.RGB color = 3; // rgb color for the rectangles
}

//
// Gets frames and does nothing with them:) Produces a signal with integer random numbers in [0..10)
// Can do an optional sleep in the process.
//
message DummyAnalysisConfig {
  required string input_frame = 1; // type: FRAME
  optional int64 sleep_duration_in_ms = 2; // Optional sleep duration
}

message DataFlowGraphConfig {
  // Descriptors to areas, like "Hármas pénztár", or "Front entrance".
  // Multiple area_descriptors can be set for different areas. It is not required to set an area_descriptor for every area_id.
  // In this case, the description is set to a default string "area_id_N", where N is equal to the area_id of that particular area.
  // However, multiple area_descriptors with the same area_id is not permitted and produce an error in construction time.
  message AreaDescriptor {
    required int32 area_id = 1;
    required string area_description = 2;
  }

  optional Input input = 1; // TODO eliminate this // specifies the input (frame source) for the graph
  repeated DataNodeConfig data_node = 2; // the data nodes
  repeated ProcessNodeConfig process_node = 3; // the process nodes
  repeated AreaDescriptor area_descriptor = 4;
}

message DataFlowGraphRunConfig {
  required Input input = 1; // specifies the input (frame source) for the graph
  optional DataFlowGraphConfig data_flow = 2; // specifies the data flow graph
  optional string data_flow_file = 3; // specifies the data flow graph file if data flow graph is not present
}

message DataFlowGraphRunnerConfig {
  optional imageproc.EnginesConfig engines = 1; // specifies the engine set usable by the graph
  optional string engines_file = 2; // specifies the engines file if engines is not present
  optional EnvironmentConfig environment = 3; // specifies the environment of the runner
  optional string environment_file = 4; // specifies the environment file if the environment is not present
  repeated DataFlowGraphRunConfig data_run = 5; // specifies the graph and input pairs
  repeated string data_run_file = 6; // specifies the file names for graph -- input pairs
}

message DrawTracksConfig {
  required string input_frame = 1;
  required string input_tracks = 2;
  required string output_frame = 3;
  optional int32 display_finished_tracks = 4; // number of finished tracks to be displayed on the screen
  optional bool display_track_ids = 5 [default = false]; //displays track ids in top-left corner
  optional bool display_property = 6 [default = false]; //displays all track-level properties on the bounding boxes
  optional imageproc.RGB property_color = 7;
  optional bool display_age_gender = 8 [default = false]; //displays age and gender in top-left corner
  optional uint32 max_display_points = 9 [default = 100];
  optional int32 offset_x = 10 [default = 0];
  optional int32 offset_y = 11 [default = 0];
  optional bool display_bb_age = 12 [default = false]; //displays age on the bounding boxes
  optional bool display_bb_gender = 13 [default = false]; //displays gender on the bounding boxes
  optional bool display_bb_direction = 14 [default = false]; //displays age on the bounding boxes
}

message GenderClassifConfig {
  message FaceDetectionConfig {
    optional float confidence_threshold = 1 [default = 0.9]; // confidence threshold for face detection
  }

  required string input_frame = 1;
  required string input_tracks = 2;
  optional string output_frame = 3;
  optional float confidence_threshold = 4 [default = 0.9];
  optional int32 required_frames = 5 [default = 5]; // minimal number of frames to make a decision
  optional float decision_weight = 6 [default = 1.5]; // multiplier by which a gender must overweight the other; must be greater than 1
  optional int32 maximum_frames = 7 [default = 20]; // maximal number of latest frames kept to make a decision
  optional FaceDetectionConfig face_detection_config = 8; // run a face detection on the tracks/detections; classify only on faces
  optional bool log_individual_genders = 9 [default = true]; // log individual genders by their track ids
}

message LookAlikeConfig {
  required string input_frame = 1;
  required string input_tracks = 2;
  required string output_frame = 3;
  required string actor_folder = 4;
  optional int32 min_duration = 5 [default = 1000]; // Min. time duration required to show actors for user
  optional int32 max_duration = 6 [default = 10000]; // Max. time duration in which features are considered
  optional string user_folder = 7 [default = ""];
}

message FrameSourceConfig {
  required string input_file_name = 1;
  required string output = 2;
}

message RotateConfig {
  enum Interpolation {
    INTER_NEAREST = 1;
    INTER_LINEAR = 2;
    INTER_CUBIC = 3;
  }
  required string input = 1;
  required string output = 2;
  required int32 angle = 3;
  optional Interpolation interpol = 4 [default = INTER_LINEAR];
}

message AnalyserLoggerConfig {
  required string input_boxes = 1;
  required string input_tracks = 2;
  required string subfolder = 3; // Name of the subfolder for logging. In case of empty string, no subfolder will be created
}

message AverageImageConfig {
  required string input = 1; // Input frame
  optional string subfolder = 2 [default = ""]; // Name of the subfolder for logging. In case of empty string, no subfolder will be created
  optional int32 updateMins = 3 [default = 1]; // Save current avg. image in every nth minutes
  optional string output = 4; // Output frame node. Avg frame with valid timestamp will be produced in every updateMin interval ending.
  //Other cases a frame will have no time stamp.
  optional uint32 nth_frame = 5 [default = 1]; // only the nth frame will be computed into the average frame
}

message DemographyNodeConfig
{
  required string input_image = 1;
  required string input_tracks = 2;
  optional bool set_result_in_tracks = 3 [default = false];
  optional bool use_head_pose = 5 [default = false];
  optional float head_pose_threshold = 6 [default = 0.9];
  optional bool use_multicrop = 7 [default = false];
  optional bool use_expectation = 8 [default = false];
  optional bool use_frame_weights = 9 [default = false];
}

message FaceDemographyCalcConfig
{
  required string input_frame = 1;
  required string input_detections = 2;
  required string output_genders = 3;
  required string output_ages = 4;
  optional bool use_multicrop = 5 [default = false];
}

message SkeletonEstimatorNodeConfig
{
  required string input_frame = 1; // type: FRAME
  required string skeletons = 2; // type: SKELETONS
}

message FacialDemographyNodeConfig
{
  enum EngineType {
    UNSPECIFIED = 1;            // Engine given by the old key "facial_demography_estimator_cfg_file_rel_path"
    FACIAL_DEMOGRAPHY_64 = 2;   // Engine using 64 pixel images, given by "facial_demography_estimator_64_cfg_file_rel_path"
    FACIAL_DEMOGRAPHY_128 = 3;  // Engine using 128 pixel images, given by "facial_demography_estimator_128_cfg_file_rel_path"
  }

  required string input_image = 1;
  required string input_tracks = 2;
  optional bool set_result_in_tracks = 3 [default = false];
  optional bool use_head_pose_3d = 4 [default = false];
  optional imageproc.HeadPose3DThreshold head_pose_3d_threshold = 5;
  optional bool use_multicrop = 6 [default = false];
  optional bool use_frame_weights = 7 [default = false];
  optional uint32 max_faces_per_frame = 8 [default = 10];
  optional EngineType engine_type = 9 [default = UNSPECIFIED];
}

message ObjDetectorEmulatorConfig
{
  required string input_bbox_file_name = 1;
  required string output_bounding_boxes = 2;
  optional bool skip_header_in_file = 3 [default = true];
}

message KalmanTrackConfig {
  required string input_bboxes = 1;
  required string output_tracks = 2;

  optional uint32 lifetimeThreshold = 5 [default = 3]; //We only care about trackers who have been alive for the
  //given lifetimeThreshold number of frames.
  optional float distanceThreshold = 6 [default = 2.0]; // We won't associate a tracker with a bounding box if the
  // distance between the two is greater than the bounding box's width multiplied by this parameter
  optional uint32 timePassedThreshold = 7 [default = 1000]; // Kill a tracker if it has gone timePassedThreshold milliseconds
  // without receiving a measurement.
  optional float dt = 8 [default = 0.2]; // Delta time, used to set up matrices for Kalman trackers.
  optional float magnitudeOfAccelerationNoise = 9 [default = 0.5]; // Magnitude of acceleration noise. Used to set up Kalman trackers.

  // parameters for feature vector based track deletion
  optional bool use_feature_vectors = 10 [default = false];
  optional string input_frame = 11;
  optional uint32 time_delay = 12 [default = 1000, deprecated = true]; // recalculate feature vectors only after time_delay ms has passed
  optional float pose_threshold = 13 [default = 0.4]; // for each track recalculate feature vector only if head pose value is bigger than this
  optional float similarity_threshold = 14 [default = 0.8]; // delete track if distance from previous feature vector is lower than this
  optional uint32 aggregation_size = 15 [default = 5, deprecated = true]; // store this amount of feature vectors for calculating an average feature vector
}

message ObjFilterNodeConfig {

  enum Strategy
  {
    NONE = 1;
    HEIGHT = 2;
    CONF = 5;
    RANDOM = 6;
  }


  required string output_bounding_boxes = 1;
  optional string input_frame = 2;
  optional string output_frame = 3;
  optional string object_detector_node_name = 4 [deprecated = true];
  optional string input_bounding_boxes = 5;

  optional int32 filter_roi_x = 6; // x coordinate of the top left corner in pixels
  optional int32 filter_roi_y = 7; // y coordinate of the top left corner in pixels
  optional int32 filter_roi_width = 8; // in pixels
  optional int32 filter_roi_height = 9; // in pixels

  optional int32 filter_detection_min_height_in_pixels = 10 [default = 160];
  optional int32 filter_detection_max_height_in_pixels = 11 [default = 160];

  optional float filter_detection_confidence_threshold = 12 [default = 0.95]; // Confidence is a real value from 0-1.

  optional string conditional_and_input_bounding_boxes = 13; // If specified and there is no detection on this channel all detection get discarded (cashier/queue problem).

  repeated Rect2D excluded_roi = 14; // excluded area(s) from the frame

  optional uint32 max_det_num = 30;
  optional Strategy selection_strategy = 31 [default = NONE];
  optional bool descending  = 32 [default = true];

}

message HeadPoseFilterConfig {
  enum EngineType {
    HEADPOSE = 1;  // HeadPose Engine provides a single scalar output
    HEADPOSE3D = 2; // HeadPose3D Engine outputs 3d rotation matrix
  }

  optional string input_frame = 1;

  required string input_bounding_boxes = 2;
  required string output_bounding_boxes = 3;


  optional uint32 valid_box_min_size = 4 [default = 128];

  optional EngineType engine_type = 5 [default = HEADPOSE];

  optional float head_pose_threshold = 6 [default = 0.8];
  optional imageproc.HeadPose3DThreshold head_pose_3d_threshold = 7;

  optional string input_poses = 8;
}

message RotatedRoiFilterConfig {
  required string input_bounding_boxes = 1;
  required string output_bounding_boxes = 2;
  optional string input_frame = 3;
  optional string output_frame = 4;

  // defining a rotated rectangle: endpoints of a line segment and the width
  required Point2D point1 = 5;
  required Point2D point2 = 6;
  required uint32 width = 7;
  optional imageproc.RGB rect_color = 8;

  optional int32 filter_detection_min_height_in_pixels = 9;
  optional int32 filter_detection_max_height_in_pixels = 10;
  optional double filter_detection_confidence_threshold = 11; // Confidence is a real value from 0-1.

  optional string conditional_and_input_bounding_boxes = 12; // If specified and there is no detection on this channel all detection get discarded (cashier/queue problem).
}

message ErrorThrowNodeConfig {
  required int32 throw_after = 1 [default = 1000];
}

message PersonReidentificationConfig
{
  required string input_frame = 1;
  required string input_tracks = 2;

  required float far = 3;
  required float max_dwell_minutes = 4;
  optional float extend_scale = 5 [default = 1.0]; //Extend the detection to a bigger or smaller square
  optional float left_scale = 6 [default = 0.75];  //Width multiplier extended to the left
  optional float right_scale = 7 [default = 0.75];  //Width multiplier extended to the right
  optional float height_scale = 8 [default = 7.0]; //Height multiplier
  optional float height_min_scale = 9 [default = 1.0]; //We only care about samples width good ratio
  optional float far_modifier = 10 [default = 0.0005]; //We only care about pairs if there is no other incoming candidate with similar similarity
  optional float area_threshold = 11 [default = 0.5]; //We don't care about person who are covered
  optional bool allow_multi_match = 12 [default = false]; //We don't pair the same incoming person with several outgoing people
}

message TrackletConfig {
  required string input_boxes = 1;
  required string output_tracklets = 2;
  optional uint32 min_num_samples_to_tracklet = 3 [default = 5];
  optional float max_width_rel_diff = 4 [default = 0.3];
  optional float max_height_rel_diff = 5 [default = 0.3];
  optional float max_rel_dist = 6 [default = 0.2];
}

message DetectionHistoryService {
  required string input_supercrops = 1;
  required string input_tracklets = 2;
  required string remote_url = 3;
  required common.ContentType content_type = 4;
  optional bool autoregister = 5 [default = false];
  optional detectionhistory.DwellTimeMetadata.DetectionType detection_type = 6;
  optional uint64 camera_id = 7 [jstype = JS_STRING];
  optional uint64 wait_for_messages_in_sec = 8 [default = 5];
}

message HeadDetectorPublisherConfig {
  required string input_supercrops = 1;
  required string input_frame = 2;
  required uint64 stream_id = 3 [jstype=JS_STRING];
}

message FaceExprConfig {
  required string input_image = 1;
  required string input_boxes = 2;
  required string output_expr = 3;
  optional float head_pose_threshold = 9 [default = 0.5];
  optional uint32 max_num_faces = 12 [default = 0];
}

message SupercropExtractorConfig {
  enum Mode {
    CPU = 0;
    PREFER_CPU = 1;
    PREFER_GPU = 2;
    GPU = 3;
  }
  enum Type {
    BODY = 0;
    FACE = 1;
  }
  required string input_frame = 1;
  required string input_boxes = 2;
  required string output_supercrops = 3;
  required Type type = 4;
  optional Mode mode = 5 [default = PREFER_CPU];
  optional float crop_scale = 6 [default = 1.5];
  optional imageproc.RGB padding_color = 7;
}

message LookAlikeDemoConfig {
  optional string video_src = 1 [default="0"];
  optional uint32 min_head_size = 2 [default=130];
  optional uint32 max_head_size = 3 [default=640];
  optional float det_confidence = 4 [default=0.9];
  optional float det_scaling_factor = 5 [default=0.4];
  optional float pose_threshold = 6 [default=0.8];
  optional uint32 max_num_of_faces = 7 [default=10];
  required string db_folder = 8;
  optional float track_iou_thresold = 9 [default=0.8];
  optional float track_cosine_threshold = 10 [default=0.7];
  optional uint32 max_frames_with_no_observation = 11 [default=1];
  optional float feature_vec_momentum = 12 [default=0.95];
  optional float box_momentum = 13 [default=0.5];
  optional float container_momentum = 14 [default=0.85];
  optional bool log_fps = 15 [default=false];
  optional float rec_threshold = 16 [default=0.6];
}

message TrackerPublisherConfig {
  required string input_tracks_orig = 1;
  optional string input_tracks_scaled = 2;
  required string input_supercrops = 3;
  required uint64 stream_id = 4 [jstype=JS_STRING];
}

message CalcFaceRecFeaturesConfig {
  required string input_image = 1;
  required string input_boxes = 2;
  required string output_boxes = 4;
  optional double valid_min_height = 5 [default=128];
  optional double valid_min_head_pose = 6 [default=0.8];
}

message MatchFaceRecFeaturesConfig {
  required string input_boxes = 1;
  required string output_boxes = 2;
  required float min_cosine_similarity = 3;
}

message KafkaOutputConfig {
  required string topic_name = 1;
  required string input_node = 2;
}

message HeadPoseCalcConfig {
  required string input_frame = 1;
  required string input_bounding_boxes = 2;
  required string output_poses = 3;
  optional uint32 valid_box_min_size = 4 [default = 128];
}

message FaceFeatureCalcConfig {
  required string input_frame = 1;
  required string input_dets = 2;
  required string output_features = 3;
}

message FullBodyCropBoxCalcConfig {
  required string input_dets = 1; //should be of detectionType=HEAD
  required string output_dets = 2; // type=PERSON
  optional float extend_scale = 3 [default = 1.0]; //Extend the detection to a bigger or smaller square
  optional float left_scale = 4 [default = 0.75];  //Width multiplier extended to the left
  optional float right_scale = 5 [default = 0.75];  //Width multiplier extended to the right
  optional float height_scale = 6 [default = 7.0]; //Height multiplier
}

message FullBodyFeatureCalcConfig {
  required string input_frame = 1;
  required string input_dets = 2; //should be of detectionType=PERSON
  required string output_features = 3;
}

message FrameInfoExtractorConfig {
  required string input_frame = 1;
  required string output_info = 2; //FRAME_INFO
}

message PolyRoiFilterConfig {
  required string input_bounding_boxes = 1;
  required string output_bounding_boxes = 2;
  repeated Point2D polygon = 5;
}

message DrawPolygonConfig {
  required string input_frame = 1;
  required string output_frame = 2;
  repeated Point2D polygon = 3;
  optional imageproc.RGB poly_line_color = 4;

  optional string input_bounding_boxes = 5; // for the alert options only, not displaying the bounding boxes
  optional bool draw_box_centers = 6 [default = false]; // for debug purposes

  // alert options
  optional bool draw_det_count = 7 [default = false];
  optional float font_resize = 8; // default = 1.0
  optional uint32 alert_threshold = 9 [default = 3]; // change font color if number of detections >= alert_threshold
  optional imageproc.RGB alert_font_color = 10;

  // offsets for drawing the polygon
  optional int32 offset_x = 11 [default = 0];
  optional int32 offset_y = 12 [default = 0];

  // filling the polygon in if the bounding boxes are equal or greater than the threshold
  optional bool fill_if_no_detection = 14 [default = false];
  optional bool fill_if_detection = 13 [default = false];
  optional uint32 filling_threshold = 15 [default = 1];
  optional imageproc.RGB no_detection_color = 17; // rgb color for fill if no detection
  optional imageproc.RGB detection_color = 16; // rgb color for the polygon and fill if there is detection
}

message DrawSkeletonConfig {
  required string input_frame = 1;
  required string output_frame = 2;
  required string input_skeletons = 3;
}
